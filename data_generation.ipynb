{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52a07942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocess as mp\n",
    "import os\n",
    "from functools import partial\n",
    "from itertools import product\n",
    "from typing import Iterable, List, Union\n",
    "\n",
    "import tqdm\n",
    "from graph_state.graph_state import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d47578c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_statistics_for_parallelized_experiments(results):\n",
    "    print(\"\\n--- Experiment Run Summary ---\")\n",
    "    saved_count = sum(1 for r in results if r.startswith(\"Saved\"))\n",
    "    skipped_count = sum(1 for r in results if r.startswith(\"Skipped\"))\n",
    "    failed_count = sum(1 for r in results if r.startswith(\"Failed\"))\n",
    "    print(f\"Successfully saved: {saved_count}\")\n",
    "    print(f\"Skipped (existed):  {skipped_count}\")\n",
    "    print(f\"Failed:             {failed_count}\")\n",
    "    if failed_count > 0:\n",
    "        print(\"\\nFailures:\")\n",
    "        for r in results:\n",
    "            if r.startswith(\"Failed\"):\n",
    "                print(f\"  - {r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84efc247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run_bell_sampling_worker(combination: tuple, num_repeats: int, output_dir: str, overwrite: bool) -> str:\n",
    "    \"\"\"\n",
    "    A single-process worker function for bell_sampling_fidelity_experiment.\n",
    "    'combination' is a tuple: (g: GraphState, err: error model (str), fidelity: float, shots: int, stab_factor: string indicating how many stabilizer elements we want to pick)\n",
    "    The process will run and save the data to the output_dir.\n",
    "\n",
    "    Returns:\n",
    "        A status string for logging.\n",
    "    \"\"\"\n",
    "    g, err, fid, shots, stab_factor = combination\n",
    "\n",
    "    if stab_factor == '2n':\n",
    "        numstab = g.n * 2\n",
    "    elif stab_factor == 'n^2':\n",
    "        numstab = g.n ** 2\n",
    "    elif stab_factor.isdigit():\n",
    "        numstab = int(stab_factor)\n",
    "    else:\n",
    "        return f\"Failed (param error): Stabilizer factor '{stab_factor}' not recognized\"\n",
    "\n",
    "    # Construct filename and check for overwrite\n",
    "    filename = f\"bell_fidelity_{g.n}q_F{fid:.3f}_err_{err}_shots_{shots}_numstab_{numstab}.npy\"\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    \n",
    "    if not overwrite and os.path.exists(filepath):\n",
    "        return f\"Skipped (exists): {filename}\"\n",
    "    \n",
    "    # Run the actual experiment\n",
    "    try:\n",
    "        # all_fidelities = [fidelity_estimation_via_random_sampling_bitpacked(g, numstab, samples)]\n",
    "        all_fidelities = []\n",
    "        for seed_i in range(num_repeats):\n",
    "            samples = bell_sampling(g, err, fid, shots, seed=seed_i)\n",
    "            est_fidelity = fidelity_estimation_via_random_sampling_bitpacked(g, numstab, samples)\n",
    "            all_fidelities.append(est_fidelity)\n",
    "            \n",
    "        # Save the result\n",
    "        np.save(filepath, np.array(all_fidelities))\n",
    "        return f\"Saved ({len(all_fidelities)} repeats): {filename}\"\n",
    "    except Exception as e:\n",
    "        return f\"Failed (runtime error): {filename} with error: {e}\"\n",
    "\n",
    "def bell_sampling_fidelity_experiment(\n",
    "    graphs: Union[GraphState, List[GraphState]],\n",
    "    err_model: Union[str, List[str]],\n",
    "    fidelity: Union[float, Iterable[float]],\n",
    "    num_shots: Union[int, Iterable[int]],\n",
    "    num_repeats: int,\n",
    "    stabilizer_factors: Union[str, List[str]],\n",
    "    output_dir: str,\n",
    "    overwrite: bool = False\n",
    "):\n",
    "    \"\"\"\n",
    "    Runs a Bell sampling fidelity experiment in parallel for all combinations of parameters. \n",
    "    Each combination is run in a separate process.\n",
    "    Arguments can be passed in as either a single instance or as a list and will be expanded.\n",
    "    \"\"\"\n",
    "    # Normalize all inputs to be lists\n",
    "    graphs_list = [graphs] if isinstance(graphs, GraphState) else list(graphs)\n",
    "    err_models = [err_model] if isinstance(err_model, str) else list(err_model)\n",
    "    fidelities = [fidelity] if isinstance(fidelity, (float, int)) else list(fidelity)\n",
    "    shots_list = [num_shots] if isinstance(num_shots, int) else list(num_shots)\n",
    "    stabilizer_factors_list = [stabilizer_factors] if isinstance(stabilizer_factors, str) else list(stabilizer_factors)\n",
    "\n",
    "    # Create the directory for saving results\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"Saving experiment data to: '{output_dir}/'\")\n",
    "\n",
    "    # Create all combinations of the parameters\n",
    "    combinations = list(product(graphs_list, err_models, fidelities, shots_list, stabilizer_factors_list))\n",
    "    \n",
    "    print(f\"Starting Bell random sampling experiment for {len(graphs_list)} graph(s), \"\n",
    "          f\"{len(err_models)} error model(s), {len(fidelities)} fidelity value(s), \"\n",
    "          f\"{len(shots_list)} shot setting(s), and {len(stabilizer_factors_list)} stabilizer factor(s).\")\n",
    "    print(f\"Total combinations (jobs) to run: {len(combinations)}\")\n",
    "    \n",
    "    # Set up the partial function for the worker\n",
    "    worker_partial = partial(\n",
    "        _run_bell_sampling_worker,\n",
    "        num_repeats=num_repeats,\n",
    "        output_dir=output_dir,\n",
    "        overwrite=overwrite\n",
    "    )\n",
    "    \n",
    "    # Set up and run the multiprocessing pool\n",
    "    num_processes = max(1, mp.cpu_count() - 2) # Leave some cores free\n",
    "    print(f\"Running on {num_processes} processes...\")\n",
    "\n",
    "    results = []\n",
    "    with mp.Pool(processes=num_processes) as pool:\n",
    "        for result in tqdm.tqdm(pool.imap_unordered(worker_partial, combinations), total=len(combinations), desc=\"Running Experiments\"):\n",
    "            results.append(result)\n",
    "\n",
    "    print_statistics_for_parallelized_experiments(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d29ea37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run_tomo_worker(combination: tuple, g: GraphState, overlap_observables: bool, num_repeats: int, output_dir: str, overwrite: bool) -> str:\n",
    "    \"\"\"\n",
    "    A single-process worker function for partial_tomo_experiment.\n",
    "    'combination' is a tuple: (err, fid, total_shots)\n",
    "    \n",
    "    Returns:\n",
    "        A status string for logging.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        err, fid, total_shots = combination\n",
    "        N = 2 ** g.n\n",
    "\n",
    "        filename = f\"tomo_{g.n}q_F{fid:.3f}_err_{err}_shots_{total_shots}.npy\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "\n",
    "        if not overwrite and os.path.exists(filepath):\n",
    "            return f\"Skipped (exists): {filename}\"\n",
    "\n",
    "        all_diags_for_combo = []\n",
    "        for seed_i in range(num_repeats):\n",
    "            exps = dge_combined(g, err, fid, total_shots, overlap_observables=overlap_observables, seed=seed_i)\n",
    "            exps = np.maximum(0, exps)\n",
    "            diags = get_diagonals_from_all_stabilizer_observables(g, exps)\n",
    "            all_diags_for_combo.append(diags)\n",
    "            \n",
    "        # Stack the results into a single 2D NumPy array\n",
    "        stacked_diags = np.array(all_diags_for_combo) # shape (num_repeats, number_of_diagonals)\n",
    "\n",
    "        # 5. Save the result\n",
    "        np.save(filepath, stacked_diags)\n",
    "        return f\"Saved ({stacked_diags.shape}): {filename}\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Provide more context in the error message\n",
    "        return f\"Failed: {filename} with error: {e}\"\n",
    "\n",
    "def partial_tomo_experiment_parallelized(\n",
    "    g: GraphState,\n",
    "    err_model: Union[str, List[str]],\n",
    "    fidelity: Union[float, Iterable[float]],\n",
    "    total_shots: Union[int, Iterable[int]],\n",
    "    overlap_observables: bool,\n",
    "    num_repeats: int,\n",
    "    output_dir: str,\n",
    "    overwrite: bool,\n",
    "):\n",
    "    \"\"\"\n",
    "    Runs a partial tomography experiment in parallel for all combinations\n",
    "    of parameters. Each combination is run in a separate process.\n",
    "\n",
    "    Args:\n",
    "        g (GraphState): The graph state object.\n",
    "        err_model (Union[str, List[str]]): A single error model string or a list of them.\n",
    "        fidelity (Union[float, Iterable[float]]): A single fidelity value or an iterable.\n",
    "        total_shots (Union[int, Iterable[int]]): A single total_shot (count) value, \n",
    "                                                 or an iterable of values.\n",
    "        num_repeats (int): The number of times to repeat the experiment\n",
    "                           for each parameter combination.\n",
    "        output_dir (str): The directory where the output .npy files will be saved.\n",
    "        overwrite (bool): If False, skips the calculation if the output file\n",
    "                          already exists. If True, it will always run and overwrite\n",
    "                          any existing file.\n",
    "    \"\"\"\n",
    "    # Normalize all inputs to be lists\n",
    "    err_models = [err_model] if isinstance(err_model, str) else list(err_model)\n",
    "    fidelities = [fidelity] if isinstance(fidelity, (float, int)) else list(fidelity)\n",
    "    shots_list = [total_shots] if isinstance(total_shots, int) else list(total_shots)\n",
    "\n",
    "    # Create the directory for saving results\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"Saving experiment data to: '{output_dir}/'\")\n",
    "\n",
    "    # Create all combinations of the parameters\n",
    "    combinations = list(product(err_models, fidelities, shots_list))\n",
    "    \n",
    "    print(f\"Starting tomography experiment for {g.n} qubits ({len(err_models)} error model(s), \"\n",
    "          f\"{len(fidelities)} fidelity value(s), and {len(shots_list)} shot setting(s).\")\n",
    "    print(f\"Total combinations (jobs) to run: {len(combinations)}\")\n",
    "    \n",
    "    # Set up the partial function for the worker\n",
    "    worker_partial = partial(\n",
    "        _run_tomo_worker,\n",
    "        g=g,\n",
    "        overlap_observables=overlap_observables,\n",
    "        num_repeats=num_repeats,\n",
    "        output_dir=output_dir,\n",
    "        overwrite=overwrite\n",
    "    )\n",
    "    \n",
    "    # Set up and run the multiprocessing pool\n",
    "    num_processes = max(1, mp.cpu_count() - 2) # Leave some cores free\n",
    "    print(f\"Running on {num_processes} processes...\")\n",
    "\n",
    "    results = []\n",
    "    with mp.Pool(processes=num_processes) as pool:\n",
    "        for result in tqdm.tqdm(pool.imap_unordered(worker_partial, combinations), total=len(combinations), desc=\"Running Experiments\"):\n",
    "            results.append(result)\n",
    "\n",
    "    print_statistics_for_parallelized_experiments(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be9754a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run_bell_sampling_diagonal_worker(combination: tuple, g: GraphState, num_repeats: int, output_dir: str, overwrite: bool) -> str:\n",
    "    # Unpack the combination tuple\n",
    "    err, fid, shots = combination\n",
    "\n",
    "    # Construct filename and check for overwrite\n",
    "    filename = f\"bell_diag_{g.n}q_F{fid:.3f}_err_{err}_shots_{shots}.npy\"\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "\n",
    "    if not overwrite and os.path.exists(filepath):\n",
    "        return f\"Skipped (exists): {filename}\"\n",
    "\n",
    "    actual_shots = (shots + 1) // 2\n",
    "    bell_samples = bell_sampling(g, err, fid, actual_shots * num_repeats, seed=num_repeats)\n",
    "    samples_split = np.split(bell_samples, num_repeats)\n",
    "\n",
    "    all_diags_for_combo = []\n",
    "\n",
    "    for samples in samples_split:\n",
    "        exps = np.array(\n",
    "            [\n",
    "                expectation_value_of_observables_from_bell_bitpacked(\n",
    "                    np.packbits(stab, bitorder=\"little\"), samples\n",
    "                )\n",
    "                for stab in g.generate_all_int_staiblizers()\n",
    "            ]\n",
    "        )\n",
    "        sqrt_exps_safe = np.sqrt(np.maximum(0, exps))\n",
    "        diags = get_diagonals_from_all_stabilizer_observables(g, sqrt_exps_safe)\n",
    "        all_diags_for_combo.append(diags)\n",
    "\n",
    "    stacked_diags = np.array(all_diags_for_combo) # Shape (num_repeats, number_of_diagonals)\n",
    "    np.save(filepath, stacked_diags)\n",
    "    return f\"Saved ({stacked_diags.shape}): {filename}\"\n",
    "\n",
    "def bell_sampling_diagonal_experiment(\n",
    "    g: GraphState,\n",
    "    err_model: Union[str, List[str]],\n",
    "    fidelity: Union[float, Iterable[float]],\n",
    "    num_shots: Union[int, Iterable[int]],\n",
    "    num_repeats: int,\n",
    "    output_dir: str,\n",
    "    overwrite: bool,\n",
    "):\n",
    "    err_models = [err_model] if isinstance(err_model, str) else list(err_model)\n",
    "    fidelities = [fidelity] if isinstance(fidelity, (float, int)) else list(fidelity)\n",
    "    shots_list = [num_shots] if isinstance(num_shots, int) else list(num_shots)\n",
    "\n",
    "    # Create the directory for saving results if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"Saving experiment data to: '{output_dir}/'\")\n",
    "\n",
    "    # Create all combinations of the parameters\n",
    "    combinations = list(product(err_models, fidelities, shots_list))\n",
    "    \n",
    "    print(f\"Starting Bell diagonal experiment for {g.n} qubits, {len(err_models)} error model(s), {len(fidelities)} fidelity value(s), and {len(shots_list)} shot setting(s).\")\n",
    "    print(f\"Starting experiment for {len(combinations)} parameter combinations...\")\n",
    "    \n",
    "    # Set up the partial function for the worker\n",
    "    worker_partial = partial(\n",
    "        _run_bell_sampling_diagonal_worker,\n",
    "        num_repeats=num_repeats,\n",
    "        g=g,\n",
    "        output_dir=output_dir,\n",
    "        overwrite=overwrite\n",
    "    )\n",
    "    \n",
    "    # Set up and run the multiprocessing pool\n",
    "    num_processes = max(1, mp.cpu_count() - 2) # Leave some cores free\n",
    "    print(f\"Running on {num_processes} processes...\")\n",
    "\n",
    "    results = []\n",
    "    with mp.Pool(processes=num_processes) as pool:\n",
    "        for result in tqdm.tqdm(pool.imap_unordered(worker_partial, combinations), total=len(combinations), desc=\"Running Experiments\"):\n",
    "            results.append(result)\n",
    "\n",
    "    print_statistics_for_parallelized_experiments(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "117d6a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run_bell_sampling_diagonal_single_run_worker(combination: tuple[GraphState, str, float, int, int], output_dir: str, overwrite: bool) -> str:\n",
    "    g, err, fid, shots, repeat_idx = combination\n",
    "\n",
    "    # Construct filename and check for overwrite\n",
    "    filename = f\"bell_scalability_{g.n}q_F{fid:.3f}_err_{err}_shots_{shots}_repeat_{repeat_idx}.npy\"\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "\n",
    "    if not overwrite and os.path.exists(filepath):\n",
    "        return f\"Skipped (exists): {filename}\"\n",
    "\n",
    "    actual_shots = (shots + 1) // 2\n",
    "    bell_samples = bell_sampling(g, err, fid, actual_shots, seed=1000 * g.n + repeat_idx)\n",
    "\n",
    "    exps = np.array(\n",
    "        [\n",
    "            expectation_value_of_observables_from_bell_bitpacked(\n",
    "                np.packbits(stab, bitorder=\"little\"), bell_samples\n",
    "            )\n",
    "            for stab in g.generate_all_int_staiblizers()\n",
    "        ]\n",
    "    )\n",
    "    sqrt_exps_safe = np.sqrt(np.maximum(0, exps))\n",
    "    diags = get_diagonals_from_all_stabilizer_observables(g, sqrt_exps_safe)\n",
    "\n",
    "    np.save(filepath, diags)\n",
    "    return f\"Saved ({diags.shape}): {filename}\"\n",
    "\n",
    "def bell_diagonal_scalability_experiment(\n",
    "    graphs: Union[GraphState, List[GraphState]],\n",
    "    err_model: Union[str, List[str]],\n",
    "    fidelity: Union[float, Iterable[float]],\n",
    "    num_shots: Union[int, Iterable[int]],\n",
    "    num_repeats: int,\n",
    "    output_dir: str,\n",
    "    overwrite: bool,\n",
    "):\n",
    "    # Normalize all inputs to be lists\n",
    "    graphs_list = [graphs] if isinstance(graphs, GraphState) else list(graphs)\n",
    "    err_models = [err_model] if isinstance(err_model, str) else list(err_model)\n",
    "    fidelities = [fidelity] if isinstance(fidelity, (float, int)) else list(fidelity)\n",
    "    shots_list = [num_shots] if isinstance(num_shots, int) else list(num_shots)\n",
    "    repeat_indices = [i for i in range(num_repeats)]\n",
    "\n",
    "    # Create the directory for saving results\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"Saving experiment data to: '{output_dir}/'\")\n",
    "\n",
    "    # Create all combinations of the parameters\n",
    "    combinations = list(product(graphs_list, err_models, fidelities, shots_list, repeat_indices))\n",
    "    \n",
    "    print(f\"Starting Bell random sampling experiment for {len(graphs_list)} graph(s), \"\n",
    "          f\"{len(err_models)} error model(s), {len(fidelities)} fidelity value(s), \"\n",
    "          f\"{len(shots_list)} shot setting(s), and {num_repeats} trials.\")\n",
    "    print(f\"Total combinations (jobs) to run: {len(combinations)}\")\n",
    "    \n",
    "    # Set up the partial function for the worker\n",
    "    worker_partial = partial(\n",
    "        _run_bell_sampling_diagonal_single_run_worker,\n",
    "        output_dir=output_dir,\n",
    "        overwrite=overwrite\n",
    "    )\n",
    "    \n",
    "    # Set up and run the multiprocessing pool\n",
    "    num_processes = max(1, mp.cpu_count() - 2) # Leave some cores free\n",
    "    print(f\"Running on {num_processes} processes...\")\n",
    "\n",
    "    results = []\n",
    "    with mp.Pool(processes=num_processes) as pool:\n",
    "        for result in tqdm.tqdm(pool.imap_unordered(worker_partial, combinations), total=len(combinations), desc=\"Running Experiments\"):\n",
    "            results.append(result)\n",
    "\n",
    "    print_statistics_for_parallelized_experiments(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75437091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving experiment data to: 'data-new/depolarizing/dge_group_nonoverlapped/'\n",
      "Starting tomography experiment for 8 qubits (1 error model(s), 1 fidelity value(s), and 50 shot setting(s).\n",
      "Total combinations (jobs) to run: 50\n",
      "Running on 12 processes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Experiments: 100%|██████████| 50/50 [01:09<00:00,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Experiment Run Summary ---\n",
      "Successfully saved: 45\n",
      "Skipped (existed):  0\n",
      "Failed:             5\n",
      "\n",
      "Failures:\n",
      "  - Failed: tomo_8q_F0.900_err_depolarizing_shots_133.npy with error: Not enough shots to split between all stabilizers (shots given: 133; total circuits to run 192)\n",
      "  - Failed: tomo_8q_F0.900_err_depolarizing_shots_115.npy with error: Not enough shots to split between all stabilizers (shots given: 115; total circuits to run 192)\n",
      "  - Failed: tomo_8q_F0.900_err_depolarizing_shots_153.npy with error: Not enough shots to split between all stabilizers (shots given: 153; total circuits to run 192)\n",
      "  - Failed: tomo_8q_F0.900_err_depolarizing_shots_100.npy with error: Not enough shots to split between all stabilizers (shots given: 100; total circuits to run 192)\n",
      "  - Failed: tomo_8q_F0.900_err_depolarizing_shots_176.npy with error: Not enough shots to split between all stabilizers (shots given: 176; total circuits to run 192)\n",
      "Saving experiment data to: 'data-new/depolarizing/dge_group_nonoverlapped/'\n",
      "Starting tomography experiment for 8 qubits (1 error model(s), 26 fidelity value(s), and 1 shot setting(s).\n",
      "Total combinations (jobs) to run: 26\n",
      "Running on 12 processes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Experiments: 100%|██████████| 26/26 [00:42<00:00,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Experiment Run Summary ---\n",
      "Successfully saved: 26\n",
      "Skipped (existed):  0\n",
      "Failed:             0\n",
      "Saving experiment data to: 'data-new/depolarizing/dge_group_overlapped/'\n",
      "Starting tomography experiment for 8 qubits (1 error model(s), 1 fidelity value(s), and 50 shot setting(s).\n",
      "Total combinations (jobs) to run: 50\n",
      "Running on 12 processes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Experiments: 100%|██████████| 50/50 [01:06<00:00,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Experiment Run Summary ---\n",
      "Successfully saved: 48\n",
      "Skipped (existed):  0\n",
      "Failed:             2\n",
      "\n",
      "Failures:\n",
      "  - Failed: tomo_8q_F0.900_err_depolarizing_shots_100.npy with error: Not enough shots to split between all stabilizers (shots given: 100; total circuits to run 129)\n",
      "  - Failed: tomo_8q_F0.900_err_depolarizing_shots_115.npy with error: Not enough shots to split between all stabilizers (shots given: 115; total circuits to run 129)\n",
      "Saving experiment data to: 'data-new/depolarizing/dge_group_overlapped/'\n",
      "Starting tomography experiment for 8 qubits (1 error model(s), 26 fidelity value(s), and 1 shot setting(s).\n",
      "Total combinations (jobs) to run: 26\n",
      "Running on 12 processes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Experiments: 100%|██████████| 26/26 [00:39<00:00,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Experiment Run Summary ---\n",
      "Successfully saved: 26\n",
      "Skipped (existed):  0\n",
      "Failed:             0\n",
      "Saving experiment data to: 'data-new/depolarizing/bsqn/'\n",
      "Starting Bell diagonal experiment for 8 qubits, 1 error model(s), 1 fidelity value(s), and 50 shot setting(s).\n",
      "Starting experiment for 50 parameter combinations...\n",
      "Running on 12 processes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Experiments: 100%|██████████| 50/50 [03:15<00:00,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Experiment Run Summary ---\n",
      "Successfully saved: 50\n",
      "Skipped (existed):  0\n",
      "Failed:             0\n",
      "Saving experiment data to: 'data-new/depolarizing/bsqn/'\n",
      "Starting Bell diagonal experiment for 8 qubits, 1 error model(s), 26 fidelity value(s), and 1 shot setting(s).\n",
      "Starting experiment for 26 parameter combinations...\n",
      "Running on 12 processes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Experiments: 100%|██████████| 26/26 [01:03<00:00,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Experiment Run Summary ---\n",
      "Successfully saved: 26\n",
      "Skipped (existed):  0\n",
      "Failed:             0\n",
      "Saving experiment data to: 'data-new/scalability/dge_group_overlapped/'\n",
      "Starting tomography experiment for 2 qubits (1 error model(s), 1 fidelity value(s), and 1 shot setting(s).\n",
      "Total combinations (jobs) to run: 1\n",
      "Running on 12 processes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Experiments: 100%|██████████| 1/1 [00:00<00:00, 2807.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Experiment Run Summary ---\n",
      "Successfully saved: 0\n",
      "Skipped (existed):  1\n",
      "Failed:             0\n",
      "Saving experiment data to: 'data-new/scalability/dge_group_overlapped/'\n",
      "Starting tomography experiment for 3 qubits (1 error model(s), 1 fidelity value(s), and 1 shot setting(s).\n",
      "Total combinations (jobs) to run: 1\n",
      "Running on 12 processes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Experiments: 100%|██████████| 1/1 [00:00<00:00, 1861.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Experiment Run Summary ---\n",
      "Successfully saved: 0\n",
      "Skipped (existed):  1\n",
      "Failed:             0\n",
      "Saving experiment data to: 'data-new/scalability/dge_group_overlapped/'\n",
      "Starting tomography experiment for 4 qubits (1 error model(s), 1 fidelity value(s), and 1 shot setting(s).\n",
      "Total combinations (jobs) to run: 1\n",
      "Running on 12 processes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Experiments: 100%|██████████| 1/1 [00:00<00:00, 2314.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Experiment Run Summary ---\n",
      "Successfully saved: 0\n",
      "Skipped (existed):  1\n",
      "Failed:             0\n",
      "Saving experiment data to: 'data-new/scalability/dge_group_overlapped/'\n",
      "Starting tomography experiment for 5 qubits (1 error model(s), 1 fidelity value(s), and 1 shot setting(s).\n",
      "Total combinations (jobs) to run: 1\n",
      "Running on 12 processes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Experiments: 100%|██████████| 1/1 [00:00<00:00, 2049.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Experiment Run Summary ---\n",
      "Successfully saved: 0\n",
      "Skipped (existed):  1\n",
      "Failed:             0\n",
      "Saving experiment data to: 'data-new/scalability/dge_group_overlapped/'\n",
      "Starting tomography experiment for 6 qubits (1 error model(s), 1 fidelity value(s), and 1 shot setting(s).\n",
      "Total combinations (jobs) to run: 1\n",
      "Running on 12 processes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Experiments: 100%|██████████| 1/1 [00:00<00:00, 1562.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Experiment Run Summary ---\n",
      "Successfully saved: 0\n",
      "Skipped (existed):  1\n",
      "Failed:             0\n",
      "Saving experiment data to: 'data-new/scalability/dge_group_overlapped/'\n",
      "Starting tomography experiment for 7 qubits (1 error model(s), 1 fidelity value(s), and 1 shot setting(s).\n",
      "Total combinations (jobs) to run: 1\n",
      "Running on 12 processes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Experiments: 100%|██████████| 1/1 [00:00<00:00, 1615.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Experiment Run Summary ---\n",
      "Successfully saved: 0\n",
      "Skipped (existed):  1\n",
      "Failed:             0\n",
      "Saving experiment data to: 'data-new/scalability/dge_group_overlapped/'\n",
      "Starting tomography experiment for 8 qubits (1 error model(s), 1 fidelity value(s), and 1 shot setting(s).\n",
      "Total combinations (jobs) to run: 1\n",
      "Running on 12 processes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Experiments: 100%|██████████| 1/1 [00:00<00:00, 2381.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Experiment Run Summary ---\n",
      "Successfully saved: 0\n",
      "Skipped (existed):  1\n",
      "Failed:             0\n",
      "Saving experiment data to: 'data-new/scalability/dge_group_overlapped/'\n",
      "Starting tomography experiment for 9 qubits (1 error model(s), 1 fidelity value(s), and 1 shot setting(s).\n",
      "Total combinations (jobs) to run: 1\n",
      "Running on 12 processes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Experiments: 100%|██████████| 1/1 [00:00<00:00, 2083.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Experiment Run Summary ---\n",
      "Successfully saved: 0\n",
      "Skipped (existed):  1\n",
      "Failed:             0\n",
      "Saving experiment data to: 'data-new/scalability/dge_group_overlapped/'\n",
      "Starting tomography experiment for 10 qubits (1 error model(s), 1 fidelity value(s), and 1 shot setting(s).\n",
      "Total combinations (jobs) to run: 1\n",
      "Running on 12 processes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Experiments: 100%|██████████| 1/1 [00:00<00:00, 1760.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Experiment Run Summary ---\n",
      "Successfully saved: 0\n",
      "Skipped (existed):  1\n",
      "Failed:             0\n",
      "Saving experiment data to: 'data-new/scalability/dge_group_overlapped/'\n",
      "Starting tomography experiment for 11 qubits (1 error model(s), 1 fidelity value(s), and 1 shot setting(s).\n",
      "Total combinations (jobs) to run: 1\n",
      "Running on 12 processes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Experiments: 100%|██████████| 1/1 [00:00<00:00, 2753.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Experiment Run Summary ---\n",
      "Successfully saved: 0\n",
      "Skipped (existed):  1\n",
      "Failed:             0\n",
      "Saving experiment data to: 'data-new/scalability/dge_group_overlapped/'\n",
      "Starting tomography experiment for 12 qubits (1 error model(s), 1 fidelity value(s), and 1 shot setting(s).\n",
      "Total combinations (jobs) to run: 1\n",
      "Running on 12 processes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Experiments: 100%|██████████| 1/1 [00:00<00:00, 1660.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Experiment Run Summary ---\n",
      "Successfully saved: 0\n",
      "Skipped (existed):  1\n",
      "Failed:             0\n",
      "Saving experiment data to: 'data-new/scalability/dge_group_overlapped/'\n",
      "Starting tomography experiment for 13 qubits (1 error model(s), 1 fidelity value(s), and 1 shot setting(s).\n",
      "Total combinations (jobs) to run: 1\n",
      "Running on 12 processes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Experiments: 100%|██████████| 1/1 [00:00<00:00, 660.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Experiment Run Summary ---\n",
      "Successfully saved: 0\n",
      "Skipped (existed):  1\n",
      "Failed:             0\n",
      "Saving experiment data to: 'data-new/scalability/dge_group_overlapped/'\n",
      "Starting tomography experiment for 14 qubits (1 error model(s), 1 fidelity value(s), and 1 shot setting(s).\n",
      "Total combinations (jobs) to run: 1\n",
      "Running on 12 processes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Experiments: 100%|██████████| 1/1 [00:00<00:00, 1437.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Experiment Run Summary ---\n",
      "Successfully saved: 0\n",
      "Skipped (existed):  1\n",
      "Failed:             0\n",
      "Saving experiment data to: 'data-new/scalability/dge_group_overlapped/'\n",
      "Starting tomography experiment for 15 qubits (1 error model(s), 1 fidelity value(s), and 1 shot setting(s).\n",
      "Total combinations (jobs) to run: 1\n",
      "Running on 12 processes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Experiments: 100%|██████████| 1/1 [00:00<00:00, 1776.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Experiment Run Summary ---\n",
      "Successfully saved: 0\n",
      "Skipped (existed):  1\n",
      "Failed:             0\n",
      "Saving experiment data to: 'data-new/scalability/bsqn/'\n",
      "Starting Bell random sampling experiment for 22 graph(s), 1 error model(s), 1 fidelity value(s), 1 shot setting(s), and 25 trials.\n",
      "Total combinations (jobs) to run: 550\n",
      "Running on 12 processes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Experiments: 100%|██████████| 550/550 [1:44:52<00:00, 11.44s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Experiment Run Summary ---\n",
      "Successfully saved: 550\n",
      "Skipped (existed):  0\n",
      "Failed:             0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We generate the data for 8 qubit graph here.\n",
    "    1. vary from F=0.5 to F=1 with N = 10^4\n",
    "    2. vary from 10^2 to 10^5 with F = 0.9 (plotting later)\n",
    "    X-axis will be log scale so we need to do log scaling X-axis (N)\n",
    "\"\"\"\n",
    "\n",
    "g = GraphState(8, \"complete\")\n",
    "shots = 10_000\n",
    "# err_model = \"single-qubit-dephasing\"\n",
    "err_model = \"depolarizing\"\n",
    "repeat = 1000\n",
    "OVERWRITE = False\n",
    "\n",
    "# first experiment\n",
    "partial_tomo_experiment_parallelized(\n",
    "    g,\n",
    "    err_model,\n",
    "    fidelity=0.9,\n",
    "    total_shots=np.round(np.logspace(start=2, stop=5, base=10, endpoint=True, num=50)).astype(int),\n",
    "    overlap_observables=False,\n",
    "    num_repeats=repeat,\n",
    "    output_dir=\"data-new/depolarizing/dge_group_nonoverlapped\",\n",
    "    overwrite=False,\n",
    ")\n",
    "\n",
    "# second experiment\n",
    "partial_tomo_experiment_parallelized(\n",
    "    g,\n",
    "    err_model,\n",
    "    np.round(np.arange(0.5, 1.01, step=0.02), decimals=3),\n",
    "    shots,\n",
    "    overlap_observables=False,\n",
    "    num_repeats=repeat,\n",
    "    output_dir=\"data-new/depolarizing/dge_group_nonoverlapped\",\n",
    "    overwrite=False,\n",
    ")\n",
    "\n",
    "# first experiment\n",
    "partial_tomo_experiment_parallelized(\n",
    "    g,\n",
    "    err_model,\n",
    "    fidelity=0.9,\n",
    "    total_shots=np.round(np.logspace(start=2, stop=5, base=10, endpoint=True, num=50)).astype(int),\n",
    "    overlap_observables=True,\n",
    "    num_repeats=repeat,\n",
    "    output_dir=\"data-new/depolarizing/dge_group_overlapped\",\n",
    "    overwrite=False,\n",
    ")\n",
    "\n",
    "# second experiment\n",
    "partial_tomo_experiment_parallelized(\n",
    "    g,\n",
    "    err_model,\n",
    "    np.round(np.arange(0.5, 1.01, step=0.02), decimals=3),\n",
    "    shots,\n",
    "    overlap_observables=True,\n",
    "    num_repeats=repeat,\n",
    "    output_dir=\"data-new/depolarizing/dge_group_overlapped\",\n",
    "    overwrite=False,\n",
    ")\n",
    "\n",
    "bell_sampling_diagonal_experiment(\n",
    "    g,\n",
    "    err_model,\n",
    "    fidelity=0.9,\n",
    "    num_shots=np.round(np.logspace(start=2, stop=5, base=10, endpoint=True, num=50)).astype(int),\n",
    "    num_repeats=repeat,\n",
    "    output_dir=\"data-new/depolarizing/bsqn\",\n",
    "    overwrite=False,\n",
    ")\n",
    "\n",
    "bell_sampling_diagonal_experiment(\n",
    "    g,\n",
    "    err_model,\n",
    "    fidelity=np.round(np.arange(0.5, 1.01, step=0.02), decimals=3),\n",
    "    num_shots=shots,\n",
    "    num_repeats=repeat,\n",
    "    output_dir=\"data-new/depolarizing/bsqn\",\n",
    "    overwrite=False,\n",
    ")\n",
    "\n",
    "# scalability experiment\n",
    "for n in range(2, 16):\n",
    "    g = GraphState(n, \"complete\")\n",
    "    partial_tomo_experiment_parallelized(\n",
    "        g,\n",
    "        err_model,\n",
    "        0.9,\n",
    "        2 * 10_000,\n",
    "        overlap_observables=True,\n",
    "        num_repeats=25,\n",
    "        output_dir=\"data-new/scalability/dge_group_overlapped\",\n",
    "        overwrite=False,\n",
    "    )\n",
    "bell_diagonal_scalability_experiment(\n",
    "    [GraphState(n, \"complete\") for n in range(2, 24)],\n",
    "    err_model,\n",
    "    fidelity=0.9,\n",
    "    num_shots=20_000,\n",
    "    num_repeats=25,\n",
    "    output_dir=\"data-new/scalability/bsqn\",\n",
    "    overwrite=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bell-sampling-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
