{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a07942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocess as mp\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from functools import partial\n",
    "from itertools import product\n",
    "from typing import Iterable, List, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "from graph_state.graph_state import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2739dc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bell_sampling_diagonal_experiment_optimize(\n",
    "    g: GraphState,\n",
    "    err_model: Union[str, List[str]],\n",
    "    fidelity: Union[float, Iterable[float]],\n",
    "    num_shots: Union[int, Iterable[int]],\n",
    "    num_repeats: int,\n",
    "    output_dir: str = \"bell_diag_data\",\n",
    "    overwrite: bool = False\n",
    "):\n",
    "    err_models = [err_model] if isinstance(err_model, str) else list(err_model)\n",
    "    fidelities = [fidelity] if isinstance(fidelity, (float, int)) else list(fidelity)\n",
    "    shots_list = [num_shots] if isinstance(num_shots, int) else list(num_shots)\n",
    "\n",
    "    # 2. Create the directory for saving results if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"Saving experiment data to: '{output_dir}/'\")\n",
    "\n",
    "    # 3. Create all combinations of the parameters\n",
    "    combinations = list(product(err_models, fidelities, shots_list))\n",
    "    \n",
    "    print(f\"Starting Bell diagonal experiment for {g.n} qubits, {len(err_models)} error model(s), {len(fidelities)} fidelity value(s), and {len(shots_list)} shot setting(s).\")\n",
    "    # print(f\"Starting experiment for {len(combinations)} parameter combinations...\")\n",
    "    # 4. Iterate through each combination, run the experiment, and save the result\n",
    "    for err, fid, shots in tqdm.tqdm(combinations, desc=\"Running Experiments\"):\n",
    "        # Construct the output filename and filepath\n",
    "        filename = f\"bell_diag_{g.n}q_F{fid:.3f}_err_{err}_shots_{shots}.npy\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        # we need two copies at a time to run Bell sampling\n",
    "        actual_shots = (shots + 1) // 2\n",
    "        \n",
    "        # Check if the file exists and skip if overwrite is False\n",
    "        if not overwrite and os.path.exists(filepath):\n",
    "            tqdm.tqdm.write(f\"    Skipping, file already exists: {filepath}\")\n",
    "            continue\n",
    "            \n",
    "        all_diags_for_combo = []\n",
    "        for _ in range(num_repeats):\n",
    "            bell_samples = bell_sampling(g, err, fid, actual_shots)\n",
    "            exps = expectation_value_of_observables_from_bell_bitpacked_parallelized(g, bell_samples)\n",
    "            sqrt_exps_safe = np.sqrt(np.maximum(0, exps))\n",
    "            diags = get_diagonals_from_all_stabilizer_observables(g, sqrt_exps_safe)\n",
    "            all_diags_for_combo.append(diags)\n",
    "            \n",
    "        # Shape will be (num_repeats, number_of_diagonals)\n",
    "        stacked_diags = np.array(all_diags_for_combo)\n",
    "        np.save(filepath, stacked_diags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd1d6d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bell_sampling_diagonal_experiment(\n",
    "    g: GraphState,\n",
    "    err_model: Union[str, List[str]],\n",
    "    fidelity: Union[float, Iterable[float]],\n",
    "    num_shots: Union[int, Iterable[int]],\n",
    "    num_repeats: int,\n",
    "    output_dir: str = \"bell_diag_data\",\n",
    "    overwrite: bool = False\n",
    "):\n",
    "    err_models = [err_model] if isinstance(err_model, str) else list(err_model)\n",
    "    fidelities = [fidelity] if isinstance(fidelity, (float, int)) else list(fidelity)\n",
    "    shots_list = [num_shots] if isinstance(num_shots, int) else list(num_shots)\n",
    "\n",
    "    # 2. Create the directory for saving results if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"Saving experiment data to: '{output_dir}/'\")\n",
    "\n",
    "    # 3. Create all combinations of the parameters\n",
    "    combinations = list(product(err_models, fidelities, shots_list))\n",
    "    \n",
    "    print(f\"Starting Bell diagonal experiment for {g.n} qubits, {len(err_models)} error model(s), {len(fidelities)} fidelity value(s), and {len(shots_list)} shot setting(s).\")\n",
    "    # print(f\"Starting experiment for {len(combinations)} parameter combinations...\")\n",
    "    # 4. Iterate through each combination, run the experiment, and save the result\n",
    "    for err, fid, shots in tqdm.tqdm(combinations, desc=\"Running Experiments\"):\n",
    "        # Construct the output filename and filepath\n",
    "        filename = f\"bell_diag_{g.n}q_F{fid:.3f}_err_{err}_shots_{shots}.npy\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        # we need two copies at a time to run Bell sampling\n",
    "        actual_shots = (shots + 1) // 2\n",
    "        \n",
    "        # Check if the file exists and skip if overwrite is False\n",
    "        if not overwrite and os.path.exists(filepath):\n",
    "            tqdm.tqdm.write(f\"    Skipping, file already exists: {filepath}\")\n",
    "            continue\n",
    "            \n",
    "        all_diags_for_combo = []\n",
    "        for _ in range(num_repeats):\n",
    "            bell_samples = bell_sampling(g, err, fid, actual_shots)\n",
    "            exps = expectation_value_of_observables_from_bell_bitpacked_parallelized(g, bell_samples)\n",
    "            sqrt_exps_safe = np.sqrt(np.maximum(0, exps))\n",
    "            diags = get_diagonals_from_all_stabilizer_observables(g, sqrt_exps_safe)\n",
    "            all_diags_for_combo.append(diags)\n",
    "            \n",
    "        # Shape will be (num_repeats, number_of_diagonals)\n",
    "        stacked_diags = np.array(all_diags_for_combo)\n",
    "        np.save(filepath, stacked_diags)\n",
    "\n",
    "def partial_tomo_experiment(\n",
    "    g: GraphState,\n",
    "    err_model: Union[str, List[str]],\n",
    "    fidelity: Union[float, Iterable[float]],\n",
    "    total_shots: Union[int, Iterable[int]],\n",
    "    num_repeats: int,\n",
    "    output_dir: str = \"tomo_data\",\n",
    "    overwrite: bool = False\n",
    "):\n",
    "    \"\"\"\n",
    "    Runs a partial tomography experiment for all combinations of the given parameters.\n",
    "\n",
    "    This function accepts single values or iterables (lists, ranges) for the\n",
    "    error model, fidelity, and shots. It then iterates through every possible\n",
    "    combination, runs the simulation, and saves the resulting diagonal values\n",
    "    of the density matrix to a .npy file.\n",
    "\n",
    "    Args:\n",
    "        g (GraphState): The graph state object.\n",
    "        err_model (Union[str, List[str]]): A single error model string or a list of them.\n",
    "        fidelity (Union[float, Iterable[float]]): A single fidelity value or an iterable.\n",
    "        num_shots_per_obs (Union[int, Iterable[int]]): A single value for shots\n",
    "            per observable, or an iterable of values.\n",
    "        output_dir (str): The directory where the output .npy files will be saved.\n",
    "        overwrite (bool): If False, skips the calculation if the output file\n",
    "                          already exists. If True, it will always run and overwrite\n",
    "                          any existing file.\n",
    "    \"\"\"\n",
    "    # 1. Normalize all inputs to be lists so we can use itertools.product\n",
    "    err_models = [err_model] if isinstance(err_model, str) else list(err_model)\n",
    "    fidelities = [fidelity] if isinstance(fidelity, (float, int)) else list(fidelity)\n",
    "    shots_list = [total_shots] if isinstance(total_shots, int) else list(total_shots)\n",
    "\n",
    "    # 2. Create the directory for saving results if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"Saving experiment data to: '{output_dir}/'\")\n",
    "\n",
    "    # 3. Create all combinations of the parameters\n",
    "    combinations = list(product(err_models, fidelities, shots_list))\n",
    "    \n",
    "    N = 2 ** g.n\n",
    "    \n",
    "\n",
    "    print(f\"Starting tomography experiment for {g.n} qubits, {len(err_models)} error model(s), {len(fidelities)} fidelity value(s), and {len(shots_list)} shot setting(s).\")\n",
    "    # print(f\"Starting experiment for {len(combinations)} parameter combinations...\")\n",
    "    # 4. Iterate through each combination, run the experiment, and save the result\n",
    "    for err, fid, budget_shots in tqdm.tqdm(combinations, desc=\"Running Experiments\"):\n",
    "        total_shots = (budget_shots // (N//2 + 2 ** (g.n - 2)) + 1) * N\n",
    "        \n",
    "        # Construct the output filename and filepath\n",
    "        filename = f\"tomo_{g.n}q_F{fid:.3f}_err_{err}_shots_{budget_shots}.npy\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        \n",
    "        # Check if the file exists and skip if overwrite is False\n",
    "        if not overwrite and os.path.exists(filepath):\n",
    "            # Using a simple print inside tqdm can mess with the progress bar,\n",
    "            # so we use tqdm.write for cleaner output.\n",
    "            tqdm.tqdm.write(f\"    Skipping, file already exists: {filepath}\")\n",
    "            continue\n",
    "            \n",
    "        # # Run the core simulation\n",
    "        # exps = partial_tomo(g, err, fid, total_shots)\n",
    "        # diags = get_diagonals_from_all_stabilizer_observables(g, exps)\n",
    "        \n",
    "        # # Save the numpy array\n",
    "        # np.save(filepath, diags)\n",
    "        # tqdm.tqdm.write(f\"    Saved results to {filepath}\")\n",
    "\n",
    "        # Collect results from all repeats for this parameter combination\n",
    "        all_diags_for_combo = []\n",
    "        for _ in range(num_repeats):\n",
    "            exps = partial_tomo(g, err, fid, total_shots)\n",
    "            diags = get_diagonals_from_all_stabilizer_observables(g, exps)\n",
    "            all_diags_for_combo.append(diags)\n",
    "            \n",
    "        # Stack the results into a single 2D NumPy array\n",
    "        # Shape will be (num_repeats, number_of_diagonals)\n",
    "        stacked_diags = np.array(all_diags_for_combo)\n",
    "\n",
    "        # print(stacked_diags.shape)\n",
    "        \n",
    "        # Save the stacked numpy array\n",
    "        np.save(filepath, stacked_diags)\n",
    "        # tqdm.tqdm.write(f\"    Saved ({stacked_diags.shape}) results to {filepath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84efc247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run_bell_sampling_worker(combination: tuple, num_repeats: int, output_dir: str, overwrite: bool) -> str:\n",
    "    \"\"\"\n",
    "    A single-process worker function for bell_sampling_fidelity_experiment.\n",
    "    'combination' is a tuple: (g, err, fid, shots, stab_factor)\n",
    "    \n",
    "    Returns:\n",
    "        A status string for logging.\n",
    "    \"\"\"\n",
    "    # 1. Unpack the combination tuple\n",
    "    g, err, fid, shots, stab_factor = combination\n",
    "\n",
    "    # 2. Calculate numstab\n",
    "    try:\n",
    "        if stab_factor == '2n':\n",
    "            numstab = g.n * 2\n",
    "        elif stab_factor == 'n^2':\n",
    "            numstab = g.n ** 2\n",
    "        elif stab_factor.isdigit():\n",
    "            numstab = int(stab_factor)\n",
    "        else:\n",
    "            raise RuntimeError(f\"Stabilizer factor '{stab_factor}' not recognized\")\n",
    "    except Exception as e:\n",
    "        return f\"Failed (param error): {e}\"\n",
    "\n",
    "    # 3. Construct filename and check for overwrite\n",
    "    filename = f\"bell_fidelity_{g.n}q_F{fid:.3f}_err_{err}_shots_{shots}_numstab_{numstab}.npy\"\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "\n",
    "    \n",
    "    if not overwrite and os.path.exists(filepath):\n",
    "        return f\"Skipped (exists): {filename}\"\n",
    "    \n",
    "    # 4. Run the actual experiment\n",
    "    try:\n",
    "        all_fidelities = []\n",
    "        # Call bell_sampling once for all repeats, then split the data\n",
    "        if (num_repeats * shots) <= 50_000_000:\n",
    "            bell_samples = bell_sampling(g, err, fid, num_repeats * shots)\n",
    "            samples_split = np.split(bell_samples, num_repeats)\n",
    "\n",
    "            for samples in samples_split:\n",
    "                est_fidelity = fidelity_estimation_via_random_sampling_bitpacked(g, numstab, samples)\n",
    "                all_fidelities.append(est_fidelity)\n",
    "        else:\n",
    "            for _ in range(num_repeats):\n",
    "                samples = bell_sampling(g, err, fid, shots)\n",
    "                est_fidelity = fidelity_estimation_via_random_sampling_bitpacked(g, numstab, samples)\n",
    "                all_fidelities.append(est_fidelity)\n",
    "        \n",
    "        # for samples in samples_split:\n",
    "        #     est_fidelity = fidelity_estimation_via_random_sampling_bitpacked(g, numstab, samples)\n",
    "        #     all_fidelities.append(est_fidelity)\n",
    "            \n",
    "        # 5. Save the result\n",
    "        np.save(filepath, np.array(all_fidelities))\n",
    "        return f\"Saved ({len(all_fidelities)} repeats): {filename}\"\n",
    "    except Exception as e:\n",
    "        return f\"Failed (runtime error): {filename} with error: {e}\"\n",
    "\n",
    "def bell_sampling_fidelity_experiment(\n",
    "    graphs: Union[GraphState, List[GraphState]],\n",
    "    err_model: Union[str, List[str]],\n",
    "    fidelity: Union[float, Iterable[float]],\n",
    "    num_shots: Union[int, Iterable[int]],\n",
    "    num_repeats: int,\n",
    "    stabilizer_factors: Union[str, List[str]],\n",
    "    output_dir: str = \"bell_fidelity_data\",\n",
    "    overwrite: bool = False\n",
    "):\n",
    "    \"\"\"\n",
    "    Runs a Bell sampling fidelity experiment in parallel for all combinations\n",
    "    of parameters. Each combination is run in a separate process.\n",
    "    \"\"\"\n",
    "    # 1. Normalize all inputs to be lists\n",
    "    graphs_list = [graphs] if isinstance(graphs, GraphState) else list(graphs)\n",
    "    err_models = [err_model] if isinstance(err_model, str) else list(err_model)\n",
    "    fidelities = [fidelity] if isinstance(fidelity, (float, int)) else list(fidelity)\n",
    "    shots_list = [num_shots] if isinstance(num_shots, int) else list(num_shots)\n",
    "    stabilizer_factors_list = [stabilizer_factors] if isinstance(stabilizer_factors, str) else list(stabilizer_factors)\n",
    "\n",
    "    # 2. Create the directory for saving results\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"Saving experiment data to: '{output_dir}/'\")\n",
    "\n",
    "    # 3. Create all combinations of the parameters, including the graph\n",
    "    combinations = list(product(graphs_list, err_models, fidelities, shots_list, stabilizer_factors_list))\n",
    "    \n",
    "    print(f\"Starting Bell random sampling experiment for {len(graphs_list)} graph(s), \"\n",
    "          f\"{len(err_models)} error model(s), {len(fidelities)} fidelity value(s), \"\n",
    "          f\"{len(shots_list)} shot setting(s), and {len(stabilizer_factors_list)} stabilizer factor(s).\")\n",
    "    print(f\"Total combinations (jobs) to run: {len(combinations)}\")\n",
    "    \n",
    "    # 4. Set up the partial function for the worker\n",
    "    worker_partial = partial(\n",
    "        _run_bell_sampling_worker,\n",
    "        num_repeats=num_repeats,\n",
    "        output_dir=output_dir,\n",
    "        overwrite=overwrite\n",
    "    )\n",
    "    \n",
    "    # 5. Set up and run the multiprocessing pool\n",
    "    num_processes = max(1, mp.cpu_count() - 2) # Leave some cores free\n",
    "    print(f\"Running on {num_processes} processes...\")\n",
    "\n",
    "    results = []\n",
    "    with mp.Pool(processes=num_processes) as pool:\n",
    "        # Use imap_unordered for efficiency, as order doesn't matter\n",
    "        # Wrap the iterator with tqdm to get a progress bar\n",
    "        for result in tqdm.tqdm(pool.imap_unordered(worker_partial, combinations), total=len(combinations), desc=\"Running Experiments\"):\n",
    "            results.append(result)\n",
    "            # Optional: print results as they come in\n",
    "            # tqdm.write(result) \n",
    "\n",
    "    print(\"\\n--- Experiment Run Summary ---\")\n",
    "    saved_count = sum(1 for r in results if r.startswith(\"Saved\"))\n",
    "    skipped_count = sum(1 for r in results if r.startswith(\"Skipped\"))\n",
    "    failed_count = sum(1 for r in results if r.startswith(\"Failed\"))\n",
    "    print(f\"Successfully saved: {saved_count}\")\n",
    "    print(f\"Skipped (existed):  {skipped_count}\")\n",
    "    print(f\"Failed:             {failed_count}\")\n",
    "    if failed_count > 0:\n",
    "        print(\"\\nFailures:\")\n",
    "        for r in results:\n",
    "            if r.startswith(\"Failed\"):\n",
    "                print(f\"  - {r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75437091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving experiment data to: 'even_more_tomo_data/'\n",
      "Starting tomography experiment for 8 qubits, 1 error model(s), 1 fidelity value(s), and 50 shot setting(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Experiments: 100%|██████████| 50/50 [18:21<00:00, 22.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving experiment data to: 'even_more_tomo_data/'\n",
      "Starting tomography experiment for 8 qubits, 1 error model(s), 26 fidelity value(s), and 1 shot setting(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Experiments: 100%|██████████| 26/26 [09:07<00:00, 21.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving experiment data to: 'even_more_bell_diag_data/'\n",
      "Starting Bell diagonal experiment for 8 qubits, 1 error model(s), 1 fidelity value(s), and 50 shot setting(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Experiments:  44%|████▍     | 22/50 [5:41:31<9:56:34, 1278.39s/it]"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We generate the data for 8 qubit graph here.\n",
    "    1. vary from F=0.5 to F=1 with N = 10^4\n",
    "    2. vary from 10^2 to 10^5 with F = 0.9 (plotting later)\n",
    "    X-axis will be log scale so we need to do log scaling X-axis (N)\n",
    "\"\"\"\n",
    "\n",
    "g = GraphState(8, \"complete\")\n",
    "shots = 10_000\n",
    "err_model = \"depolarizing\"\n",
    "repeat = 1000\n",
    "OVERWRITE = False\n",
    "\n",
    "# first experiment\n",
    "partial_tomo_experiment(\n",
    "    g,\n",
    "    err_model,\n",
    "    fidelity=0.9,\n",
    "    total_shots=np.round(np.logspace(start=2, stop=5, base=10, endpoint=True, num=50)).astype(int),\n",
    "    num_repeats=repeat,\n",
    "    output_dir=\"even_more_tomo_data\",\n",
    "    overwrite=False,\n",
    ")\n",
    "\n",
    "# second experiment\n",
    "partial_tomo_experiment(\n",
    "    g,\n",
    "    err_model,\n",
    "    np.round(np.arange(0.5, 1.01, step=0.02), decimals=3),\n",
    "    shots,\n",
    "    repeat,\n",
    "    \"even_more_tomo_data\",\n",
    "    False,\n",
    ")\n",
    "\n",
    "bell_sampling_diagonal_experiment(\n",
    "    g,\n",
    "    err_model,\n",
    "    fidelity=0.9,\n",
    "    num_shots=np.round(np.logspace(start=2, stop=5, base=10, endpoint=True, num=50)).astype(int),\n",
    "    num_repeats=repeat,\n",
    "    output_dir=\"even_more_bell_diag_data\",\n",
    "    overwrite=False,\n",
    ")\n",
    "\n",
    "bell_sampling_diagonal_experiment(\n",
    "    g,\n",
    "    err_model,\n",
    "    np.round(np.arange(0.5, 1.01, step=0.02), decimals=3),\n",
    "    shots,\n",
    "    repeat,\n",
    "    \"even_more_bell_diag_data\",\n",
    "    False,\n",
    ")\n",
    "\n",
    "# # scalability experiment\n",
    "\n",
    "# for n in range(2, 13):\n",
    "#     g = GraphState(n, \"complete\")\n",
    "#     partial_tomo_experiment(\n",
    "#         g,\n",
    "#         err_model,\n",
    "#         0.9,\n",
    "#         2 * 10_000,\n",
    "#         25,\n",
    "#         \"tomo_data\",\n",
    "#         False,\n",
    "#     )\n",
    "#     bell_sampling_diagonal_experiment(\n",
    "#         g,\n",
    "#         err_model,\n",
    "#         0.9,\n",
    "#         20_000,\n",
    "#         25,\n",
    "#         \"bell_diag_data\",\n",
    "#         False,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55a2919e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving experiment data to: 'bell_fidelity_data/'\n",
      "Starting Bell random sampling experiment for 1 graph(s), 3 error model(s), 1 fidelity value(s), 1 shot setting(s), and 50 stabilizer factor(s).\n",
      "Total combinations (jobs) to run: 150\n",
      "Running on 12 processes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Experiments: 100%|██████████| 150/150 [21:00:31<00:00, 504.21s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Experiment Run Summary ---\n",
      "Successfully saved: 66\n",
      "Skipped (existed):  84\n",
      "Failed:             0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "graphs = [GraphState(i, 'complete') for i in range(21, 201)]\n",
    "shots = 5_000\n",
    "err_models = ['depolarizing', 'single-qubit-dephasing', 'bimodal']\n",
    "# err_models = ['depolarizing']\n",
    "stab_factors = '2n'\n",
    "repeat = 50\n",
    "OVERWRITE = False\n",
    "\n",
    "# testing scalability of fidelity estimation\n",
    "# bell_sampling_fidelity_experiment(graphs, err_models, 0.53, shots, repeat, stab_factors)\n",
    "\n",
    "# testing varying stabs\n",
    "num_qubits = 40\n",
    "shots = 1_000_000\n",
    "repeat = 50\n",
    "stabilizer_counts = np.logspace(np.log10(num_qubits), np.log10(num_qubits**3), 50).astype(int)\n",
    "stab_factors = list(map(str, stabilizer_counts))\n",
    "bell_sampling_fidelity_experiment(GraphState(40), err_models, 0.53, shots, repeat, stab_factors)\n",
    "\n",
    "# testing varying shots\n",
    "# num_qubits = 40\n",
    "# shots = np.logspace(2, 5, 50).astype(int)\n",
    "# stab_factors = '2n'\n",
    "# bell_sampling_fidelity_experiment(GraphState(40), err_models, 0.53, shots, repeat, stab_factors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bell-sampling-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
